# -*- coding: utf-8 -*-
"""lab05.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e2oYcHd48GI3yjP9i5OGnejVBJ1RUaaq
"""

#importing necessary libraries
import pandas as pd
import numpy as np

df=pd.read_csv('mushroom edibility classification dataset.csv')
df.head()

df.shape

#Dropping the 'Unnamed:0' column
df.drop('Unnamed: 0', axis=1, inplace=True)

df.shape

df.head()

df.isnull().sum()

#dropping the rows with null values
print("Shape of dataframe before dropping:", df.shape)
df = df.dropna(axis = 0, subset = ['cap-shape','cap-color'])
print("Shape after dropping:", df.shape)

#check whether null values succesfully removed
df.isnull().sum()

#now going to encode categorical values
#first check which columns have categorical values
df.info()

#checking unique values
df['class'].unique()

df['bruises'].unique()

#encoding categorical values
from sklearn.preprocessing import LabelEncoder

# Set up the LabelEncoder object
enc = LabelEncoder()

# Apply the encoding to the "class" column
df['class'] = enc.fit_transform(df['class'])

print(df[['class']].head())

# Apply the encoding to the "bruises" column

df['bruises'] = enc.fit_transform(df['bruises'])

print(df[['bruises']].head(10))

#feature scaling
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

scaler.fit(df)

# transform data
df_scaled = scaler.transform(df)

print("per-feature minimum before scaling:\n {}".format(df.to_numpy().min(axis=0)))
print("per-feature maximum before scaling:\n {}".format(df.to_numpy().max(axis=0)))

print("per-feature minimum after scaling:\n {}".format(
    df_scaled.min(axis=0)))
print("per-feature maximum after scaling:\n {}".format(
    df_scaled.max(axis=0)))

from sklearn.model_selection import train_test_split
y=pd.DataFrame(df_scaled[:,0])
X_train, X_test, y_train, y_test = train_test_split(df_scaled[:,1:], df_scaled[:,0], test_size=0.25, stratify=y, random_state=0)

#testing
from sklearn.neighbors import KNeighborsClassifier

knn=KNeighborsClassifier()

knn.fit(X_train, y_train)

print("Test set accuracy: {:.2f}".format(knn.score(X_test, y_test)))