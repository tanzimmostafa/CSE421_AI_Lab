# -*- coding: utf-8 -*-
"""422lab_assign_6

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mo7FhPApLvS03LKljJamihvIhmg41n4E
"""

#importing necessary libraries
import pandas as pd
import numpy as np

df=pd.read_csv('mushroom edibility classification dataset.csv')
df.head()

df.shape

#Dropping the 'Unnamed:0' column
df.drop('Unnamed: 0', axis=1, inplace=True)

df.shape

df.head()

df.isnull().sum()

#dropping the rows with null values
print("Shape of dataframe before dropping:", df.shape)
df = df.dropna(axis = 0, subset = ['cap-shape','cap-color'])
print("Shape after dropping:", df.shape)

#check whether null values succesfully removed
df.isnull().sum()

#now going to encode categorical values
#first check which columns have categorical values
df.info()

#checking unique values
df['class'].unique()

df['bruises'].unique()

#encoding categorical values
from sklearn.preprocessing import LabelEncoder

# Set up the LabelEncoder object
enc = LabelEncoder()

# Apply the encoding to the "class" column
df['class'] = enc.fit_transform(df['class'])

print(df[['class']].head())

# Apply the encoding to the "bruises" column

df['bruises'] = enc.fit_transform(df['bruises'])

print(df[['bruises']].head(10))

df.head()

df.shape

#df.iloc[:,1:]

#df.iloc[:,0]

#feature scaling
from sklearn.preprocessing import StandardScaler
scaler= StandardScaler()
df_scaled=scaler.fit_transform(df.iloc[:,1:])#is a numpy array

#new_df_scaled.iloc[:,-1].to_numpy()

#df.iloc[:,0].isnull().sum()

#df.isnull().sum()

#Now dividing the dataset into 8:2 train-test split
from sklearn.model_selection import train_test_split
y=pd.DataFrame(df.iloc[:,0])
x_train, x_test, y_train, y_test = train_test_split(df_scaled[:,:], df.iloc[:,0].to_numpy(), test_size=0.2, stratify=y, random_state=0)

print("Training set: x->{} , y->{} \n Testing set: x->{} , y->{}".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))

#Now going to apply SVM,MLPClassifier and Random Forest on the dataset
#Applying SVC
from sklearn.svm import SVC
svc = SVC(kernel="linear")
svc.fit(x_train, y_train)

print("Training accuracy of the model is {:.2f}".format(svc.score(x_train, y_train)))
print("Testing accuracy of the model is {:.2f}".format(svc.score(x_test, y_test)))
score_svc=svc.score(x_test, y_test)

#Applying Ensemble Classifier (Random Forest)
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=50)
rfc.fit(x_train, y_train)

print("The Training accuracy of the model is {:.2f}".format(rfc.score(x_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(rfc.score(x_test, y_test)))
score_rf=rfc.score(x_test, y_test)

#Applying MLPClassifier
from sklearn.neural_network import MLPClassifier
nnc=MLPClassifier(hidden_layer_sizes=(7), activation="relu", max_iter=10000)

nnc.fit(x_train, y_train)

print("The Training accuracy of the model is {:.2f}".format(nnc.score(x_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(nnc.score(x_test, y_test)))
score_mlpc=nnc.score(x_test, y_test)

df_scaled.shape

#Now going to perform dimensionality reduction using PCA
from sklearn.decomposition import PCA 
pca = PCA(n_components=9)

principal_components= pca.fit_transform(df_scaled)
#print(principal_components.shape)

#type(principal_components)

sum(pca.explained_variance_ratio_)

principal_df = pd.DataFrame(data=principal_components, columns=["pc1","pc2","pc3","pc4","pc5","pc6","pc7","pc8","pc9"])
principal_df.head(15)

class_numpiarray=df["class"].to_numpy()
#type(class_numpiarray)

class_df=pd.DataFrame(data=class_numpiarray,columns=["class"])

class_df.isnull().sum()

#class_df.head(15)

main_df=pd.concat([principal_df, class_df], axis=1)

#main_df.isnull().sum()

X= main_df.drop("class" , axis=1)
y= main_df["class"]

#Now dividing the dataset into 8:2 train-test split
y2=pd.DataFrame(y)
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y2, random_state=0)

#print("Training set: x->{} , y->{} \n Testing set: x->{} , y->{}".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))

#Now again going to apply SVM,MLPClassifier and Random Forest on the dataset after having perfromed PCA
#Applying SVC
from sklearn.svm import SVC
svc = SVC(kernel="linear")
svc.fit(x_train, y_train)

print("Training accuracy of the model is {:.2f}".format(svc.score(x_train, y_train)))
print("Testing accuracy of the model is {:.2f}".format(svc.score(x_test, y_test)))
pca_score_svc=svc.score(x_test, y_test)

#Applying Ensemble Classifier (Random Forest)
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=50)
rfc.fit(x_train, y_train)

print("The Training accuracy of the model is {:.2f}".format(rfc.score(x_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(rfc.score(x_test, y_test)))
pca_score_rf=rfc.score(x_test, y_test)

#Applying MLPClassifier
from sklearn.neural_network import MLPClassifier
nnc=MLPClassifier(hidden_layer_sizes=(7), activation="relu", max_iter=10000)
nnc.fit(x_train, y_train)

print("The Training accuracy of the model is {:.2f}".format(nnc.score(x_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(nnc.score(x_test, y_test)))
pca_score_mlpc=nnc.score(x_test, y_test)

#Now going to compare the accuracy of the pre-PCA and post-PCA results and plot them against each other in a bar graph.
#Comparing the accuracy and plotting them as a bar chart using matplotlib
import matplotlib.pyplot as plt; plt.rcdefaults()
import numpy as np
import matplotlib.pyplot as plt

objects = ('Pre-PCA SVC', 'Post-PCA SVC','Pre-PCA MLPClassifier', 'Post-PCA MLPClassifier','Pre-PCA Random Forest', 'Post-PCA Random Forest' )
y_pos = np.arange(len(objects))
performance = [score_svc, pca_score_svc, score_mlpc, pca_score_mlpc, score_rf, pca_score_rf]

plt.bar(y_pos, performance, align='center', alpha=0.5)
plt.xticks(y_pos, objects)
plt.ylabel('Accuracy')
plt.xlabel('Classifier')
plt.title('Bar chart comparing accuracy of pre-PCA and post-PCA results')
plt.xticks(rotation=90)

plt.show()

